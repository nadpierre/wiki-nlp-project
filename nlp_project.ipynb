{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9be9711",
   "metadata": {},
   "source": [
    "# Wikipedia Music Genres NLP Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe6dc4",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e68579",
   "metadata": {},
   "source": [
    "This notebook performs an NLP on random articles collected from [Wikipedia](https://en.wikipedia.org/). It explored different feature extraction and clustering methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef81e48",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47d46009",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg' (/opt/anaconda3/lib/python3.12/site-packages/scipy/linalg/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodel_api\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/gensim/__init__.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/gensim/corpora/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[1;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/gensim/interfaces.py:19\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[1;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/gensim/matutils.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m entropy\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_blas_funcs, triu\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlapack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m psi  \u001b[38;5;66;03m# gamma function utils\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'triu' from 'scipy.linalg' (/opt/anaconda3/lib/python3.12/site-packages/scipy/linalg/__init__.py)"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as model_api\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aafbc5d",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/w/api.php'\n",
    "csv_path = 'data/wiki_articles.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c819f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_titles(n:int) -> np.array:\n",
    "    titles = []\n",
    "    while len(titles) < n:\n",
    "        try:\n",
    "            params = {\n",
    "                'action': 'query',\n",
    "                'list': 'random',\n",
    "                'rnnamespace': 0,  # Only articles\n",
    "                'rnlimit': min(50, n - len(titles)),\n",
    "                'format': 'json'\n",
    "            }\n",
    "            response = requests.get(url, params=params)\n",
    "            data = response.json()\n",
    "            batch = [item['title'] for item in data['query']['random']]\n",
    "            titles.extend(batch)\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            print('Error:', e)\n",
    "            time.sleep(1)\n",
    "    return np.array(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4345f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_text(title:str) -> str:\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'prop': 'extracts',\n",
    "        'explaintext': True,\n",
    "        'titles': title\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        pages = response.json()['query']['pages']\n",
    "        page = next(iter(pages.values()))\n",
    "        return page.get('extract', '')\n",
    "    except Exception as e:\n",
    "        print(f'Error fetching {title}: {e}')\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aaaed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted_sections(text):\n",
    "    unwanted_sections = [\n",
    "        r'==\\s*See also\\s*==',\n",
    "        r'==\\s*References\\s*==',\n",
    "        r'==\\s*Further reading\\s*==',\n",
    "        r'==\\s*External links\\s*==',\n",
    "        r'==\\s*Notes\\s*==',\n",
    "        r'==\\s*Sources\\s*==',\n",
    "        r'==\\s*Bibliography\\s*==',\n",
    "        r'==\\s*Footnotes\\s*=='\n",
    "    ]\n",
    "    \n",
    "    pattern = re.compile('|'.join(unwanted_sections), re.IGNORECASE)\n",
    "    match = pattern.search(text)\n",
    "    \n",
    "    if match:\n",
    "        return text[:match.start()].strip()\n",
    "    else:\n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bffa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_clean(text):\n",
    "    core = remove_unwanted_sections(text)\n",
    "    core = re.sub(r'\\n{2,}', '\\n', core)\n",
    "    return core.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ce1c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_list_to_csv(data:list[dict], csv_path:str) -> None:\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tif not os.path.isfile(csv_path):\n",
    "\t\tdf.to_csv(csv_path, index=False)\n",
    "\telse:\n",
    "\t\tdf.to_csv(csv_path, index=False, header=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc3a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 10000 random articles from Wikipedia\n",
    "titles = get_random_titles(10000)\n",
    "chunks = np.array_split(titles, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a295aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data in chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "\tprint(f'Chunk {i + 1}/{len(chunks)}')\n",
    "\twiki_list = []\n",
    "\tfor title in chunk:\n",
    "\t\ttext = get_article_text(title)\n",
    "\t\tif text and len(text) > 300:  # Filter out very short pages\n",
    "\t\t\twiki_list.append({\n",
    "\t\t\t\t'title': title,\n",
    "\t\t\t\t'text': full_clean(text)\n",
    "\t\t\t})\n",
    "\t\ttime.sleep(0.5) # Sleep for 500 ms to avoid rate-limiting\n",
    "\texport_list_to_csv(wiki_list, csv_path)\n",
    "\tprint(f'Added {len(wiki_list)}/{len(chunk)} articles to CSV file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6e734",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d60d1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biff Schlitzer</td>\n",
       "      <td>Victor Joseph \"Biff\" Schlitzer (December 4, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prabhash Kumar</td>\n",
       "      <td>Prabhash Kumar is an Indian politician, farmer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Carlos Formation</td>\n",
       "      <td>The San Carlos Formation is a geological forma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023 in Ohio</td>\n",
       "      <td>The following is a list of events of the year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009 Iowa special elections</td>\n",
       "      <td>The 2009 Iowa state special elections were hel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0               Biff Schlitzer   \n",
       "1               Prabhash Kumar   \n",
       "2         San Carlos Formation   \n",
       "3                 2023 in Ohio   \n",
       "4  2009 Iowa special elections   \n",
       "\n",
       "                                                text  \n",
       "0  Victor Joseph \"Biff\" Schlitzer (December 4, 18...  \n",
       "1  Prabhash Kumar is an Indian politician, farmer...  \n",
       "2  The San Carlos Formation is a geological forma...  \n",
       "3  The following is a list of events of the year ...  \n",
       "4  The 2009 Iowa state special elections were hel...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c64174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8595 entries, 0 to 8594\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   8595 non-null   object\n",
      " 1   text    8595 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 134.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "617f004c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                     List of volcanoes in El Salvador\n",
       "text     This is a list of active and extinct volcanoes...\n",
       "Name: 5992, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get smallest test\n",
    "index = df['text'].str.len().idxmin()\n",
    "df.iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e293cbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                                  Divided differences\n",
       "text     In mathematics, divided differences is an algo...\n",
       "Name: 5321, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get biggest test\n",
    "index = df['text'].str.len().idxmax()\n",
    "df.iloc[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56964854",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ee8d9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Victor Joseph \"Biff\" Schlitzer (December 4, 18...\n",
       "1    Prabhash Kumar is an Indian politician, farmer...\n",
       "2    The San Carlos Formation is a geological forma...\n",
       "3    The following is a list of events of the year ...\n",
       "4    The 2009 Iowa state special elections were hel...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep text from article\n",
    "X = df['text']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336d325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15404</th>\n",
       "      <th>15405</th>\n",
       "      <th>15406</th>\n",
       "      <th>15407</th>\n",
       "      <th>15408</th>\n",
       "      <th>15409</th>\n",
       "      <th>15410</th>\n",
       "      <th>15411</th>\n",
       "      <th>15412</th>\n",
       "      <th>15413</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>victor</td>\n",
       "      <td>joseph</td>\n",
       "      <td>biff</td>\n",
       "      <td>schlitzer</td>\n",
       "      <td>december</td>\n",
       "      <td>4</td>\n",
       "      <td>1884</td>\n",
       "      <td>–</td>\n",
       "      <td>january</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prabhash</td>\n",
       "      <td>kumar</td>\n",
       "      <td>is</td>\n",
       "      <td>an</td>\n",
       "      <td>indian</td>\n",
       "      <td>politician</td>\n",
       "      <td>farmer</td>\n",
       "      <td>and</td>\n",
       "      <td>a</td>\n",
       "      <td>member</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>san</td>\n",
       "      <td>carlos</td>\n",
       "      <td>formation</td>\n",
       "      <td>is</td>\n",
       "      <td>a</td>\n",
       "      <td>geological</td>\n",
       "      <td>formation</td>\n",
       "      <td>in</td>\n",
       "      <td>west</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>following</td>\n",
       "      <td>is</td>\n",
       "      <td>a</td>\n",
       "      <td>list</td>\n",
       "      <td>of</td>\n",
       "      <td>events</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>year</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>2009</td>\n",
       "      <td>iowa</td>\n",
       "      <td>state</td>\n",
       "      <td>special</td>\n",
       "      <td>elections</td>\n",
       "      <td>were</td>\n",
       "      <td>held</td>\n",
       "      <td>throughout</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8590</th>\n",
       "      <td>uroš</td>\n",
       "      <td>lajovic</td>\n",
       "      <td>is</td>\n",
       "      <td>a</td>\n",
       "      <td>slovenian</td>\n",
       "      <td>conductor</td>\n",
       "      <td>and</td>\n",
       "      <td>professor</td>\n",
       "      <td>he</td>\n",
       "      <td>has</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8591</th>\n",
       "      <td>vegetable</td>\n",
       "      <td>chips</td>\n",
       "      <td>also</td>\n",
       "      <td>referred</td>\n",
       "      <td>to</td>\n",
       "      <td>as</td>\n",
       "      <td>veggie</td>\n",
       "      <td>chips</td>\n",
       "      <td>are</td>\n",
       "      <td>chips</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8592</th>\n",
       "      <td>josé</td>\n",
       "      <td>de</td>\n",
       "      <td>aquino</td>\n",
       "      <td>pereira</td>\n",
       "      <td>april</td>\n",
       "      <td>22</td>\n",
       "      <td>1920</td>\n",
       "      <td>–</td>\n",
       "      <td>november</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8593</th>\n",
       "      <td>november</td>\n",
       "      <td>2005</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>court</td>\n",
       "      <td>bombing</td>\n",
       "      <td>was</td>\n",
       "      <td>a</td>\n",
       "      <td>simultaneous</td>\n",
       "      <td>suicide</td>\n",
       "      <td>bombing</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8594</th>\n",
       "      <td>the</td>\n",
       "      <td>camp</td>\n",
       "      <td>lejeune</td>\n",
       "      <td>incident</td>\n",
       "      <td>refers</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>outbreak</td>\n",
       "      <td>of</td>\n",
       "      <td>hostilities</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8595 rows × 15414 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1           2          3          4           5      \\\n",
       "0        victor     joseph        biff  schlitzer   december           4   \n",
       "1      prabhash      kumar          is         an     indian  politician   \n",
       "2           the        san      carlos  formation         is           a   \n",
       "3           the  following          is          a       list          of   \n",
       "4           the       2009        iowa      state    special   elections   \n",
       "...         ...        ...         ...        ...        ...         ...   \n",
       "8590       uroš    lajovic          is          a  slovenian   conductor   \n",
       "8591  vegetable      chips        also   referred         to          as   \n",
       "8592       josé         de      aquino    pereira      april          22   \n",
       "8593   november       2005  bangladesh      court    bombing         was   \n",
       "8594        the       camp     lejeune   incident     refers          to   \n",
       "\n",
       "           6             7           8            9      ... 15404 15405  \\\n",
       "0           1884             –     january            4  ...  None  None   \n",
       "1         farmer           and           a       member  ...  None  None   \n",
       "2     geological     formation          in         west  ...  None  None   \n",
       "3         events            of         the         year  ...  None  None   \n",
       "4           were          held  throughout         2009  ...  None  None   \n",
       "...          ...           ...         ...          ...  ...   ...   ...   \n",
       "8590         and     professor          he          has  ...  None  None   \n",
       "8591      veggie         chips         are        chips  ...  None  None   \n",
       "8592        1920             –    november           17  ...  None  None   \n",
       "8593           a  simultaneous     suicide      bombing  ...  None  None   \n",
       "8594         the      outbreak          of  hostilities  ...  None  None   \n",
       "\n",
       "     15406 15407 15408 15409 15410 15411 15412 15413  \n",
       "0     None  None  None  None  None  None  None  None  \n",
       "1     None  None  None  None  None  None  None  None  \n",
       "2     None  None  None  None  None  None  None  None  \n",
       "3     None  None  None  None  None  None  None  None  \n",
       "4     None  None  None  None  None  None  None  None  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "8590  None  None  None  None  None  None  None  None  \n",
       "8591  None  None  None  None  None  None  None  None  \n",
       "8592  None  None  None  None  None  None  None  None  \n",
       "8593  None  None  None  None  None  None  None  None  \n",
       "8594  None  None  None  None  None  None  None  None  \n",
       "\n",
       "[8595 rows x 15414 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize texts by removing punctuation and special characters\n",
    "# and lowercasing everything\n",
    "replaceDict = dict({\n",
    "'{':\" \", '}':\" \", ',':\"\", '.':\" \", '!':\" \", '\\\\':\" \", '/':\" \", '$':\" \", '%':\" \",\n",
    "'^':\" \", '?':\" \", '\\'':\" \", '\"':\" \", '(':\" \", ')':\" \", '*':\" \", '+':\" \", '-':\" \",\n",
    "'=':\" \", ':':\" \", ';':\" \", ']':\" \", '[':\" \", '`':\" \", '~':\" \",\n",
    "})\n",
    "\n",
    "rep = dict((re.escape(k),v) for k, v in replaceDict.items())\n",
    "pattern = re.compile('|'.join(rep.keys()))\n",
    "\n",
    "def replacer(text):\n",
    "    return rep[re.escape(text.group(0))]\n",
    "\n",
    "words = X.str.replace(pattern, replacer, regex=True).str.lower().str.split()\n",
    "words = pd.DataFrame(words.tolist())\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535b260",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4817c1",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37e43958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.02091569, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(X)\n",
    "tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34d61ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8595, 163381)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05461587",
   "metadata": {},
   "source": [
    "#### GloVe Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783964a",
   "metadata": {},
   "source": [
    "#### Sentence Embeddings from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF, BERT embeddings\n",
    "# Word embeddings like Word2Vec, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use HF feature extraction model that does all those steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99954af7",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72634ee0",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94438ecf",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6368774",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d00a36",
   "metadata": {},
   "source": [
    "## Evaluation and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca07d101",
   "metadata": {},
   "source": [
    "### Visualize Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a417d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  t-SNE, UMAP, PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada6b5e1",
   "metadata": {},
   "source": [
    "### Analyse Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729bc9d9",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
